# Breguet-Watch-Scraper

# ğŸ’¼ Projet IA â€“ Structuration intelligente de donnÃ©es horlogÃ¨res

Ce dÃ©pÃ´t contient le code et les ressources associÃ©s au projet de **collecte et dâ€™analyse automatisÃ©e de fiches produits horlogÃ¨res**, avec un focus sur la marque **Breguet**.

---

## ğŸ§© Objectif du projet

Lâ€™objectif est de **scraper automatiquement** les fiches montres disponibles sur la plateforme [EveryWatch.com](https://www.everywatch.com), puis de **structurer les descriptions textuelles techniques** Ã  lâ€™aide dâ€™un modÃ¨le dâ€™intelligence artificielle avancÃ© (GPT-4 via lâ€™API OpenAI).

Ce pipeline vise Ã  gÃ©nÃ©rer une base de donnÃ©es exploitable, normalisÃ©e, et prÃªte Ã  Ãªtre utilisÃ©e dans des analyses mÃ©tier (pricing, veille concurrentielle, enrichissement de catalogue, etc.).

---

## âš™ï¸ Technologies utilisÃ©es

- **Python 3.12+**
- **Playwright** : pour le scraping dynamique des pages web
- **OpenAI (GPT-4)** : pour lâ€™extraction intelligente des informations techniques
- **Pandas / JSON / Excel** : pour la manipulation et lâ€™export des donnÃ©es
- **Jupyter Notebook** : pour les tests et lâ€™itÃ©ration rapide

- 
## ğŸ—‚ï¸ Structure du dÃ©pÃ´t

```bash
.
â”œâ”€â”€ (E1) Document dâ€™analyse stratÃ©gique.pdf   # Analyse des choix technologiques et IA
â”œâ”€â”€ (E2) Compte rendu de projet.pdf           # Compte rendu vulgarisÃ© Ã  destination du client
â”œâ”€â”€ Daytona-db-sample.xlsx        # Base de donnÃ©es contenant des montres dÃ©jÃ  rÃ©cupÃ©rÃ©es manuellement par le client
â”œâ”€â”€ README.md                     # Documentation du projet
â”œâ”€â”€ Watchfeed.csv                 # Export brut des fiches scrappÃ©es
â”œâ”€â”€ all_watches_data.json         # DonnÃ©es horlogÃ¨res structurÃ©es
â”œâ”€â”€ login.py                      # Script de connexion / authentification gÃ©nÃ©rique
â”œâ”€â”€ login_mac.py                  # Variante du script login pour macOS
â”œâ”€â”€ re_logic_bis2.py              # Script de scrapping de 4800 montres
â”œâ”€â”€ remplissage_excel.ipynb       # Notebook afin de rÃ©partir les donnÃ©es scrapper depuis le json vers excel
